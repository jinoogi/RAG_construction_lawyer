import streamlit as st
import pickle
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
import json
import re

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë²•ë¥  AI ì±—ë´‡", layout="wide")

# App ì œëª©
st.title("ğŸ§‘â€âš–ï¸ ë²•ë¥  AI ì±—ë´‡ - RAG ê¸°ë°˜")

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def load_faiss_index():
    # ì ˆëŒ€ ê²½ë¡œë¡œ FAISS ì¸ë±ìŠ¤ ì„¤ì •
    faiss_index_path = r"/Users/jeong-jinwook/civil_capstone/combined_faiss"
    return FAISS.load_local(faiss_index_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)

# combined_laws ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def load_combined_laws():
    with open("combined_laws.pkl", "rb") as file:
        return pickle.load(file)

# FAISS ì¸ë±ìŠ¤ ë° combined_laws ë¶ˆëŸ¬ì˜¤ê¸°
try:
    vectorstore = load_faiss_index()
    combined_laws = load_combined_laws()
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    st.stop()

# Retriever ì„¤ì •
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ìœ„ ì¡°í•­ í•„í„°ë§ í•¨ìˆ˜ (ë¹ˆë„ ê¸°ë°˜ ì ìˆ˜í™”)
def filter_sub_laws_by_keywords(uuids, sub_laws, query, max_count=2):
    """
    í•˜ìœ„ ì¡°í•­ì„ UUIDë¡œ í•„í„°ë§í•˜ê³ , query í‚¤ì›Œë“œì™€ ê´€ë ¨ì„±ì„ ì ìˆ˜í™”í•˜ì—¬ ìƒìœ„ max_countê°œì˜ í•˜ìœ„ ì¡°í•­ì„ ë°˜í™˜.
    """
    query_keywords = re.findall(r"\w+", query)  # ì •ê·œì‹ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    scored_sub_laws = []

    for sub_law in sub_laws:
        sub_uuid = sub_law[0]["ìì‹ ì˜uuid"]
        if sub_uuid in uuids:  # UUIDë¡œ í•„í„°ë§
            score = 0
            for content in sub_law[1]:
                for keyword in query_keywords:
                    score += content.count(keyword)  # í‚¤ì›Œë“œ ë¹ˆë„ë§Œí¼ ì ìˆ˜ ì¶”ê°€

            if score > 0:  # ê´€ë ¨ì„±ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                scored_sub_laws.append((sub_law, score))

    # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ í›„ ìƒìœ„ max_countê°œ ë°˜í™˜
    scored_sub_laws = sorted(scored_sub_laws, key=lambda x: x[1], reverse=True)
    return [sub_law[0] for sub_law in scored_sub_laws[:max_count]]

# join_laws í•¨ìˆ˜
def join_laws(query, retriever, sub_laws):
    output = []
    retrieved_docs = retriever.get_relevant_documents(query)
    
    for doc in retrieved_docs:
        # ë©”ì¸ ì¡°í•­ ì •ë³´ ìˆ˜ì§‘
        main_law_data = {
            "ì¡°í•­ëª…": doc.metadata.get("ì¡°í•­ëª…", ""),
            "ë²•ë ¹ëª…": doc.metadata.get("ë²•ë ¹ëª…", ""),
            "ë³¸ë¬¸": doc.page_content,
            "í•˜ìœ„ì¡°í•­ë“¤": []
        }
        
        # ë³¸ë¬¸ ì¡°í•­ì˜ í•˜ìœ„ì¡°í•­ UUIDë¡œ sub_laws ì¡°íšŒ
        uuids = doc.metadata.get("í•˜ìœ„ì¡°í•­ uuid", [])
        matching_sub_laws = filter_sub_laws_by_keywords(uuids, sub_laws, query, max_count=2)  # ìµœëŒ€ 3ê°œ ì„ íƒ
        
        # í•˜ìœ„ ì¡°í•­ë“¤ ì¶”ê°€
        for sub_law in matching_sub_laws:
            main_law_data["í•˜ìœ„ì¡°í•­ë“¤"].append({
                "í•˜ìœ„ì¡°í•­": " ".join(sub_law[1])
            })
        
        output.append(main_law_data)
    
    # JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    for law in output:
        law["ë³¸ë¬¸"] = re.sub(r"<[^>]*>", "", law["ë³¸ë¬¸"]).replace("\n", " ").strip()
        if "í•˜ìœ„ì¡°í•­ë“¤" in law:
            for sub_law in law["í•˜ìœ„ì¡°í•­ë“¤"]:
                sub_law["í•˜ìœ„ì¡°í•­"] = re.sub(r"<[^>]*>", "", sub_law["í•˜ìœ„ì¡°í•­"]).replace("\n", " ").strip()

    return json.dumps(output, indent=4, ensure_ascii=False)

# ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜
def generate_response(query, related_laws):
    prompt = f"""You are a friendly legal AI assistant performing Question-Answering tasks. Your mission is to answer the given question based on the provided legal articles (Related_Law_Articles).
Use the provided legal articles (Related_Law_Articles) to answer the given question (question).
All answers must be based on evidence, and the referenced articles must be explicitly cited at the end of each sentence.
When citing sub-articles, ensure that the content of the law being referenced is clearly identifiable.
Each sentence should be concise and start on a new line, but the overall response should be detailed and lengthy.
Answer in Korean. However, technical terms or names should not be translated and should remain as they are.

#Question:
{query}

#Related_Law_Articles:
{related_laws}

#Answer:"""
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0.7)
    response = llm.invoke(prompt)
    return response.content

# Streamlit UI
query = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ìœ í•´ìœ„í—˜ë°©ì§€ ê³„íšì„œë¥¼ ì œì¶œí•´ì•¼ í•˜ë‚˜ìš”?")
if query:
    with st.spinner("ë²•ë ¹ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
        # ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰
        sub_laws = []
        for law in combined_laws:
            sub_laws.extend(law["sub_laws"])
        related_laws = join_laws(query, retriever, sub_laws)
        
        # LLMì„ ì‚¬ìš©í•´ ë‹µë³€ ìƒì„±
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = generate_response(query, related_laws)
        
        # ê²°ê³¼ ì¶œë ¥
        st.subheader("ğŸ” ê²€ìƒ‰ëœ ë²•ë ¹")
        st.json(json.loads(related_laws))
        
        st.subheader("ğŸ’¡ ë‹µë³€")
        st.write(response)